---
title: "Merging Multiple Dirichelt Distributions"
author: "Rob Schick, PhD and Michail Papathomas, PhD"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Merging Multiple Dirichelt Distributions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Herein we describe the second of the two steps needed to go from the (multiple) raw values we elicited as Beta distributions from the expert into a coherent probability framework. What we describe here is how to take the individual Dirichlet distributions we created in the first vignette, and create a merged Dirichlet. As before we will outline the mathematics, use a toy example, and then work through a proper example with code.

## Mathematical Background
Let's assume we have a prior with $m$ categories that is a mixture of Dirichlet's:

$$f^0_{(n)} = \sum_{j = 1}^J k_j^{(0)} f_j^{(0)} (n)$$

$$f^0_{(n)} = \sum_{j = 1}^J k_j^{(0)} Dir\left( d^{(0)}_{j1}, \ldots, d^{(0)}_{jm} \right)$$

Note the non-standard notation where the $^{(0)}$ superscript refers to the prior, and later $^{(1)}$ will refer to the posterior.

To sample from the above distribution, we choose a component distribution $j$ with probability $k_j^{(0)}$. We then sample from $f_j^{(0)} (n)$, assuming our data are $(n_1, \ldots, n_m)$. The posterior for each component is given as:

$$ f_j^{(0)} (n) = Dir \left( d^{(0)}_{j1} + n_1, \ldots, d^{(0)}_{jm} + n_m\right ),$$

with normalising constant $C$ given as:

$$ C_j = \frac{\prod^M_{m=1}\Gamma(d_{jm}^{(0)} + n_m)}{\Gamma \left( \sum^M_{m = 1} (d_{jm}^{(0)} + n_m)\right)}.$$

The overall posterior is:

$$ f^{(1)} (n) = \sum^J_{j=1} k_j^{(1)} f^{(1)}_j (n),$$

with 

$$k_j^{(1)} = \frac{k_j^{(0)} C_j}{\sum_{j=1}^J k_j^{(0)} C_j} .$$

To sample, you choose a component distribution $j$with probability $k_j^{(0)}$. We then sample from $f_j^{(1)} (n) = Dir \left( d^{(0)}_{j1} + n_1, \ldots, d^{(0)}_{jm} + n_m\right )$, assuming our data are $(n_1, \ldots, n_m)$.

